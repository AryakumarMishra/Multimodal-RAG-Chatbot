{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5250c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Simple PDF File This is (inde:\n",
      "a small demonstration .pdf file -\n",
      "\n",
      "for use in the\n",
      "\n",
      "just\n",
      "Virtual Mechanics\n",
      "\n",
      "tutorials. More text. And more text.\n",
      "\n",
      "And more text.\n",
      "\n",
      "And more text. And more\n",
      "\n",
      "text. And more text. And more text.\n",
      "\n",
      "And more text.\n",
      "text. And more\n",
      "more text. And\n",
      "text. And more\n",
      "more text. And\n",
      "text. And more\n",
      "And more text.\n",
      "text. And more\n",
      "\n",
      "And more text.\n",
      "nace 2\n",
      "\n",
      "And more text. And more\n",
      "text. Boring, zzzzz. And\n",
      "more text. And more\n",
      "text. And more text. And\n",
      "more text. And more\n",
      "text. And more text.\n",
      "And more text. And more\n",
      "text. And more text.\n",
      "Even more. Continued on\n"
     ]
    }
   ],
   "source": [
    "# Extracting text from images\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "img = Image.open('documents/sample.jpg')\n",
    "img = img.convert('L')\n",
    "\n",
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "print(text.replace(\"\\x0c\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a simple text editor\n"
     ]
    }
   ],
   "source": [
    "# Image Captioning using BLIP\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "image = Image.open(\"documents/sample.jpg\")\n",
    "image = image.convert('L')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\") #type: ignore (pylance error; code works fine)\n",
    "\n",
    "outputs = model.generate(**inputs) #type: ignore (pylance error; code works fine)\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True) #type: ignore (pylance error; code works fine)\n",
    "print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30b2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': 'A Simple PDF File This is (inde:\\na small demonstration .pdf file -\\n\\nfor use in the\\n\\njust\\nVirtual Mechanics\\n\\ntutorials. More text. And more text.\\n\\nAnd more text.\\n\\nAnd more text. And more\\n\\ntext. And more text. And more text.\\n\\nAnd more text.\\ntext. And more\\nmore text. And\\ntext. And more\\nmore text. And\\ntext. And more\\nAnd more text.\\ntext. And more\\n\\nAnd more text.\\nnace 2\\n\\nAnd more text. And more\\ntext. Boring, zzzzz. And\\nmore text. And more\\ntext. And more text. And\\nmore text. And more\\ntext. And more text.\\nAnd more text. And more\\ntext. And more text.\\nEven more. Continued on', 'Caption': 'a simple text editor'}\n"
     ]
    }
   ],
   "source": [
    "# Combined Text Exraction and Image Captioning (Tesseract + BLIP)\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = ( r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" )\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "img = Image.open('documents/sample.jpg')\n",
    "img = img.convert('L')\n",
    "inputs = processor(images=img, return_tensors=\"pt\") #type: ignore (pylance error; code works fine)\n",
    "\n",
    "text = pytesseract.image_to_string(img)\n",
    "outputs = model.generate(**inputs) #type: ignore (pylance error; code works fine)\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True) #type: ignore (pylance error; code works fine)\n",
    "\n",
    "\n",
    "# Empty dictionary to store the final output\n",
    "response = {}\n",
    "\n",
    "response[\"Text\"] = text.replace(\"\\x0c\", \"\").strip()\n",
    "response[\"Caption\"] = caption\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c14c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Simple PDF File \\nThis is a small demonstration .pdf file \\njust for use in the Virtual Mechanics tutorials. More text. And more  \\ntext. And more text. And more text. And more text. \\nAnd more text. And more text. And more text. And more text. And more.  \\ntext. And more text. Boring, zzzzz. And more text. And more text. And \\nmore text. And more text. And more text. And more text. And more text.  \\nAnd more text. And more text. \\nAnd more text. And more text. And more text. And more text. And more  \\ntext. And more text. And more text. Even more. Continued on page 2 ... \\nSimple PDF File 2 \\n...continued from page 1. Yet more text. And more text. And more text.  \\nAnd more text. And more text. And more text. And more text. And more  \\ntext. Oh, how boring typing this stuff. But not as boring as watching  \\npaint dry. And more text. And more text. And more text. And more text.  \\nBoring. More, a little more text. The end, and just as well. \\n']\n"
     ]
    }
   ],
   "source": [
    "# Extracting texts from PDFs (PyMuPDF)\n",
    "\n",
    "import fitz\n",
    "\n",
    "pdf_response = []\n",
    "\n",
    "doc = fitz.open('documents/sample.pdf')\n",
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    pdf_response.append(text)\n",
    "\n",
    "print(pdf_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cfcbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Column header (TH)', 'Column header (TH)', 'Column header (TH)'], ['Row header (TH)', 'Data cell (TD)', 'Data cell (TD)'], ['Row header(TH)', 'Data cell (TD)', 'Data cell (TD)']], [['Role', 'Actor'], ['Main character', 'Daniel Radcliffe'], ['Sidekick 1', 'Rupert Grint'], ['Sidekick 2', 'Emma Watson'], ['Lovable ogre', 'Robbie Coltrane'], ['Professor', 'Maggie Smith'], ['Headmaster', 'Richard Harris']], [['Non-current assets', '2010', '2009', '2008'], ['Property', '345', '445', '222'], ['Investment', '567', '654', '423'], ['Intangibles', '423', '123', '453']], [['', '2011', None, '2010 restated', None], ['General income', '', '250,000', '', '200,000'], ['Increase in value, WIP', '', '15,000', '', '30,000'], ['', '', '265,000', '', '230,000'], ['Administrative costs', None, None, None, None], ['Staff costs', '(200,000)', '', '(150,000)', ''], ['Early departures', '(10,000)', '', '(20,000)', ''], ['Other', '(25,000)', '', '(10,000)', ''], ['Depreciation', '(10,000)', '', '(10,000)', ''], ['Programme costs', None, None, None, None], ['Impairment loss', '(10,000)', '', '(5,000)', ''], ['Other', '(5,000)', '', '(5,000)', ''], ['', '(260,000)', '', '(200,000)', ''], ['Surplus', '', '5,000', '', '30,000']], [['', '2008', None, '2009', None], ['Name', 'Yes', 'No', 'Yes', 'No'], ['Bob', '2', '5', '6', '7'], ['Sue', '3', '8', '4', '7'], ['Sam', '[data relating to both columns in\\na single cell spanning both]', None, '[data relating to both columns in\\na single cell spanning both]', None]], [['', '2006', '2007', '2008', '2009'], ['Economics', 'No', 'Yes', 'Yes', 'Yes'], ['International relations', 'No', 'No', 'No', 'No'], ['Philosophy', 'No', 'No', 'No', 'No'], ['Politics', 'No', 'No', 'No', 'No'], ['Mathematics', 'Yes', 'No', 'No', 'No'], ['English', 'Yes', 'Yes', 'Yes', 'Yes']], [['Country', '1980', '1990', '2000', '2010'], ['Afghanistan', '0.78', '1.48', '2.16', '3.33'], ['Albania', '8.89', '9.67', '9.89', '10.38'], ['Algeria', '4.74', '3.33', '5.50', '7.24'], ['Andorra', '4.98', '5.63', '9.09', '10.35'], ['Angola', '-', '-', '4.42', '4.42']], [['Expenditure by function Â£million', None, '2009/10', '2010/11'], ['Policy functions', 'Financial', '22.5', '30.57'], [None, 'Information', '10.2', '14.8'], [None, 'Contingency', '2.6', '1.2'], ['Remunerated functions', 'Agency services', '44.7', '35.91'], [None, 'Payments', '22.41', '19.88'], [None, 'Banking', '22.90', '44.23'], [None, 'Other', '12.69', '10.32']], [['', '2010', '2009', '2008'], ['Non-current assets', None, None, None], ['Buildings', '345', '445', '222'], ['Investment', '567', '654', '423'], ['Intangibles', '423', '123', '453'], ['Current assets', None, None, None], ['Trade', '435', '634', '231'], ['Cash', '524', '123', '482'], ['Other', '223', '211', '254'], ['Current liabilities', None, None, None], ['Trade liabilities', '154', '125', '421'], ['Financial debt', '231', '474', '572'], ['Provisions', '111', '312', '347']], [['Name', 'Apples', 'Pears'], ['Bob Scott', '20', '25'], ['Susan. P. Arnold-Jones, BA, FRSA, MD', '24', '15'], ['Sam Holder-Dickinson', '14', '10']], [['', 'South America', 'Asia', 'Africa', 'Australia'], ['2010', None, None, None, None], ['Highest average', '523.6', '467.4', '405.0', '340.5'], ['Highest in 24 hours', '73.1', '54.1', '27.2', '66.3'], ['Highest in 12 hours', '42.4', '30.1', '15.9', '40.3'], ['2009', None, None, None, None], ['Highest average', '487.7', '453.6', '398.7', '356'], ['Highest in 24 hours', '67.2', '53.2', '44.3', '53.8'], ['Highest in 12 hours', '34.7', '34.1', '29.8', '31.0'], ['2008', None, None, None, None], ['Highest average', '496.7', '444.3', '502.1', '399.6'], ['Highest in 24 hours', '44.2', '56.7', '32.1', '63.2'], ['Highest in 12 hours', '30.1', '32.7', '21.9', '40.2']]]\n"
     ]
    }
   ],
   "source": [
    "# Extracting tables from PDFs (PyMuPDF, using Fitz)\n",
    "\n",
    "import fitz\n",
    "\n",
    "pdf_table_response = []\n",
    "\n",
    "doc = fitz.open('documents/sample-tables.pdf')\n",
    "for page in doc:\n",
    "    tabs = page.find_tables()\n",
    "    if tabs.tables:\n",
    "        pdf_table_response.append(tabs[0].extract())\n",
    "\n",
    "\n",
    "print(pdf_table_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39695eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe you are just talking nonsense\n"
     ]
    }
   ],
   "source": [
    "# Extracting texts from Audio (MP3, WAV, etc. files, using SpeechRecognition and Pydub (for extracting large audio files))\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "filename = 'documents/sample.wav'\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(filename) as source:\n",
    "    audio_data = r.record(source)\n",
    "    text = r.recognize_google(audio_data) #type: ignore (pylance error; code works fine)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ee782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continued code for audio extraction, but for larger audio files, taken from the documentation (https://thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python)\n",
    "\n",
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "def transcribe_audio(path):\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        text = r.recognize_google(audio_listened) #type: ignore (pylance error; code works fine)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_large_audio_transcription_on_silence(path):\n",
    "    \"\"\"Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\"\"\"\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename)\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Error:\", str(e))\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"\n",
    "            print(chunk_filename, \":\", text)\n",
    "            whole_text += text\n",
    "    return whole_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
